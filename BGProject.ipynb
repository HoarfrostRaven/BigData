{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOq5S8JD1i6dNERlAKmaG1n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoarfrostRaven/BigData/blob/main/BGProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare the dataset"
      ],
      "metadata": {
        "id": "W-slv4jGsigh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://snap.stanford.edu/data/web-Google.txt.gz\n",
        "!gzip -d web-Google.txt.gz"
      ],
      "metadata": {
        "id": "vBrWu6gUqQxU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c8fc892-e383-4ca4-c7cb-e646c2b70af7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-28 22:21:25--  https://snap.stanford.edu/data/web-Google.txt.gz\n",
            "Resolving snap.stanford.edu (snap.stanford.edu)... 171.64.75.80\n",
            "Connecting to snap.stanford.edu (snap.stanford.edu)|171.64.75.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21168784 (20M) [application/x-gzip]\n",
            "Saving to: ‘web-Google.txt.gz’\n",
            "\n",
            "web-Google.txt.gz   100%[===================>]  20.19M  18.1MB/s    in 1.1s    \n",
            "\n",
            "2025-03-28 22:21:26 (18.1 MB/s) - ‘web-Google.txt.gz’ saved [21168784/21168784]\n",
            "\n",
            "gzip: web-Google.txt already exists; do you wish to overwrite (y or n)? n\n",
            "\tnot overwritten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCXIZ8LXp8zD",
        "outputId": "b94c25eb-4447-4ba2-b1f4-f37fd7699b3e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVFcipjRp-Pw",
        "outputId": "2620b15d-43b5-47ff-b680-cb3fd660f538"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  web-Google.txt  web-Google.txt.gz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EaKhS0f_kRE9"
      },
      "outputs": [],
      "source": [
        "# !pip install pyspark\n",
        "from pyspark import SparkConf\n",
        "from pyspark.context import SparkContext\n",
        "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the file, ignore first 4 lines and split the data\n",
        "data = (\n",
        "    sc.textFile(\"/content/web-Google.txt\")\n",
        "    .filter(lambda line: line.strip() and not line.startswith('#'))\n",
        "    .map(lambda line: tuple(map(int, line.split())))\n",
        ")"
      ],
      "metadata": {
        "id": "XWM3KNZOqgtm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.take(5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blZas8QJsP7l",
        "outputId": "c13f69ed-8fc7-4e20-a1ca-4c35df2499f6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 11342), (0, 824020), (0, 867923), (0, 891835), (11342, 0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CCF-Iterate"
      ],
      "metadata": {
        "id": "q4B-gy9ZuS67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import StorageLevel\n",
        "\n",
        "def connected_components_ccf(data, num_partitions = 1):\n",
        "    \"\"\"\n",
        "    Computes connected components using the CCF algorithm.\n",
        "\n",
        "    Args:\n",
        "        data: An RDD of edges represented as tuples (node1, node2).\n",
        "              Example: sc.parallelize([(1, 2), (2, 3), (2, 4), (4, 5), (6, 7), (7, 8)])\n",
        "\n",
        "    Returns:\n",
        "        An RDD of edges representing the connected components.\n",
        "        Example: sc.parallelize([(2, 1), (3, 1), (4, 1), (5, 1), (7, 6), (8, 6)])\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize bidirectional edges with partition optimization\n",
        "    edges = (data.flatMap(lambda x: [(x[0], x[1]), (x[1], x[0])])\n",
        "             .distinct()\n",
        "             .repartition(num_partitions)\n",
        "             .persist(StorageLevel.MEMORY_AND_DISK))  # Spill to disk if OOM\n",
        "\n",
        "    converged = False\n",
        "    iteration = 0\n",
        "    prev_edges = None  # Track previous iteration's data\n",
        "\n",
        "    while not converged:\n",
        "        iteration += 1\n",
        "        print(f\"--- Iteration {iteration} ---\")\n",
        "\n",
        "        # Filter first to reduce data volume before reduce\n",
        "        filtered = edges.filter(lambda x: x[1] < x[0]).cache()\n",
        "\n",
        "        # Compute minimum neighbors with partition preservation\n",
        "        min_values = filtered.reduceByKey(min, numPartitions=num_partitions).cache()\n",
        "        filtered.unpersist()  # Release intermediate data immediately\n",
        "\n",
        "        # Join with partition alignment to minimize shuffle\n",
        "        new_edges = (min_values.join(edges, numPartitions=num_partitions)\n",
        "                     .filter(lambda x: x[1][0] != x[1][1])  # Remove self-edges\n",
        "                     .map(lambda x: (x[1][1], x[1][0]))     # Remap edges\n",
        "                     .cache())\n",
        "\n",
        "        if new_edges.isEmpty():\n",
        "            converged = True\n",
        "            result = min_values\n",
        "        else:\n",
        "            # Release data from two iterations back\n",
        "            if prev_edges is not None:\n",
        "                prev_edges.unpersist()\n",
        "\n",
        "            # Track current edges for future cleanup\n",
        "            prev_edges = edges\n",
        "\n",
        "            # Update edges with partition optimization\n",
        "            edges = (min_values.union(new_edges)\n",
        "                     .flatMap(lambda x: [(x[0], x[1]), (x[1], x[0])])\n",
        "                     .repartition(num_partitions)\n",
        "                     .persist(StorageLevel.MEMORY_AND_DISK))\n",
        "\n",
        "            # Release current iteration's intermediates\n",
        "            min_values.unpersist()\n",
        "            new_edges.unpersist()\n",
        "\n",
        "    # Final cleanup\n",
        "    edges.unpersist()\n",
        "    return result"
      ],
      "metadata": {
        "id": "YVj6TpKoEmiZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example data for testing\n",
        "test_data = sc.parallelize([(1, 2), (2, 3), (2, 4), (4, 5), (6, 7), (7, 8)])\n",
        "\n",
        "# Run the connected_components_ccf algorithm\n",
        "result = connected_components_ccf(test_data)\n",
        "\n",
        "# Collect and print the result\n",
        "print(\"Connected components:\", result.collect())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLHVN6RN-6dd",
        "outputId": "1d2d4d78-b7fd-4868-9349-173446abf7c7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Iteration 1 ---\n",
            "--- Iteration 2 ---\n",
            "--- Iteration 3 ---\n",
            "--- Iteration 4 ---\n",
            "Connected components: [(4, 1), (2, 1), (3, 1), (5, 1), (7, 6), (8, 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute connected components using the CCF algorithm\n",
        "connected_components = connected_components_ccf(data, 200)\n",
        "\n",
        "# Print the results\n",
        "print(connected_components.collect())"
      ],
      "metadata": {
        "id": "iktS6jBly6vU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}